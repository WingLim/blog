[{"categories":null,"contents":"","date":"Nov 26","permalink":"/projects/hugo-tania-theme/","tags":null,"title":"Hugo Tania Theme"},{"categories":null,"contents":"","date":"Apr 22","permalink":"/projects/caddy-webhook/","tags":null,"title":"Caddy Webhook"},{"categories":null,"contents":"我的博客部署流程如下：\n 写文章并推送到 username.github.io 仓库的 hugo 分支。 GitHub Actions 自动构建并推送到 main 分支。 GitHub 发送 webhook 请求到自有服务器，服务器拉取更新。  不使用 GitHub Page 的原因主要是在国内访问太慢，而且有服务器闲置，正好用来部署博客。\n而使用 GitHub Actions 先构建推送到 main，然后再在服务器上拉取的原因是可以在 GitHub Page 上有一个备份，服务器出现故障时可以先 302 重定向到 GitHub Page，解决故障后切换回来。\n为了实现这个流程，在服务器上需要用到一个服务：Caddy\nCaddy 是基于 go 编写的 web 服务器，相比于 nginx 和 apache 的优点就是能自动申请 SSL 证书，自动更新证书。\n当然，有人会说这类文章网上已经有很多了，为什么还要重复再写一篇。一个重要的原因是网上的的文章都是基于 Caddy V1 版本，而在 Caddy 更新到 V2 版本后，之前的插件都已经失效了。\n本着用新不用旧的原则，我也将 Caddy 更新到 V2，但也因为这样需要重新配置第 3 步的部署流程。\n为了实现第 3 步，我给 Caddy 写了一个模块：caddy-webhook，下面通过具体的步骤来展示如何使用这个模块。\n建立仓库 建立一个 username.github.io 的仓库会自动配置 GitHub Page，并且可以通过直接访问 username.github.io 来访问到 main 分支中的静态页面。\n克隆仓库并进入\ngit clone username.github.io cd username.github.io 新建并切换到 hugo 分支\ngit checkout -b hugo 在当前目录创建一个 hugo 站点\nhugo new site . 然后就可以在 hugo 分支中撰写文章了\n使用 GitHub Actions 创建 github workflows 文件夹\nmkdir -p .github/workflows 进入 workflows 文件夹并新建 hugo 工作流\ncd .github/workflows touch hugo.yml hugo.yml 内容如下：\n因为在 Hugo 站点中，大多数人都是使用 submodule 来配置主题，所以我们需要使用 checkout@v2 的 submodules: 'recursive' 来获取主题，否则在构建博客时会无法找到主题模版而无法生成静态页面。\n同时推荐使用 extended 版本的 Hugo，附带了 scss 的功能，以免使用的主题没有提供编译后的 css 文件。\nsecrets.GITHUB_TOKEN 是 GitHub Actions 中自带的，无需再手动配置。\nname:Deploy Hugo to Github Pageson:push:branches:- hugojobs:build-deploy:runs-on:ubuntu-lateststeps:- uses:actions/checkout@v2with:submodules:\u0026#39;recursive\u0026#39;- name:Setup Hugouses:peaceiris/actions-hugo@v2with:hugo-version:\u0026#39;0.83.1\u0026#39;extended:true- name:Buildrun:hugo --minify- name:Deployuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.GITHUB_TOKEN }}publish_dir:./publicpublish_branch:main部署 Caddy 创建文件夹用于保存 Caddy 的文件数据\nmkdir -p caddy/data 初始化日志及配置文件\ncd caddy touch access.log touch Caddyfile 使用 docker 进行部署，winglim/caddy 是我构建的包含了 caddy-webhook 模块的镜像。\ndocker run -itd \\  -p 80:80 -p 443:443 -v $PWD/Caddyfile:/etc/caddy/Caddyfile \\  -v $PWD/access.log:/var/log/access.log \\  -v $PWD/data:/data\\  winglim/caddy 如果不想使用 docker 进行部署的话，可以自己手动编译一个带 caddy-webhook 模块的 caddy\n# 注意 go install package@tag 只在 go 1.16 及以上版本才支持 go install github.com/caddyserver/xcaddy/cmd/xcaddy@latest # 低于 go 1.16 版本请使用 go get go get -v github.com/caddyserver/xcaddy/cmd/xcaddy@latest xcaddy build \\ \t--with github.com/WingLim/caddy-webhook Caddyfile 内容如下：\nexample.com { tls yourmail@example.com encode zstd gzip log { output file /var/log/access.log } root blog file_server route /webhook { webhook { repo https://github.com/username/username.github.io.git branch main path blog secret yoursecret } } } 最后，我们就实现了文章开头所说的工作流程，剩下的就是写一些有价值的文章了。\n","date":"May 08","permalink":"/post/caddy-hugo-github-actions-for-blog/","tags":["Caddy","Hugo","GitHub Actions"],"title":"Caddy2 + Hugo + Github Actions 的自动化部署博客方案"},{"categories":null,"contents":"Docker为我们提供了一个一键式部署代码环境的方式，透过Docker Image我们可以不关心当前的操作系统的环境，只需要拉取镜像下来即可获得一致的运行环境。\n但仍存在一个问题，如果你直接使用 docker build ，构建出来的镜像是基于你当前机器的CPU架构。当然，你也可以将代码和 Dockerfile 拉到虚拟机中进行构建，但这会花费很多时间。\n通过 GitHub Actions，我们可以在 push 代码的时候，自动进行多架构的镜像构建，不再需要手动构建并推送到 Docker Hub 等镜像仓库中。\n下面是一个示例：\n这是我在 kea-dhcp4 中使用的 GitHub Actions 构建脚本的一部分\n要推送到 DockerHub，则需要在 repo 的 sercrets 中设置 DockerHub 的用户名及 TOKEN\nTOKEN 的生成参考：Managing access tokens\n要推送到 GitHub 的镜像仓库，即 ghcr.io 中则需要设置 PAT(Personal Access Token)\nCR_PAT 的生成参考：Migrating to GitHub Container Registry for Docker images\nname:buildon:push:branches:[main ]paths-ignore:- \u0026#34;README.md\u0026#34;jobs:build:runs-on:ubuntu-lateststeps:-name:Checkoutuses:actions/checkout@v2-name:Set up QEMUuses:docker/setup-qemu-action@v1-name:Set up Docker Buildxuses:docker/setup-buildx-action@v1-name:Login to DockerHubuses:docker/login-action@v1with:username:${{ secrets.DOCKERHUB_USERNAME }}password:${{ secrets.DOCKERHUB_TOKEN }}-name:Login to GitHub Container Registryuses:docker/login-action@v1 # 在 sercrets 中设置 CR_PAT# with:registry:ghcr.iousername:${{ github.repository_owner }}password:${{ secrets.CR_PAT }}-name:Build kea-dhcp4uses:docker/build-push-action@v2with:context:.file:./Dockerfileplatforms:linux/amd64,linux/arm64,linux/armpush:truetags:|winglim/kea-dhcp4:latest ghcr.io/winglim/kea-dhcp4:latest如果你没有对 docker/setup-qemu-action 进行设置的话，默认支持的platforms如下：\n linux/amd64 linux/arm64 linux/riscv64 linux/ppc64le linux/s390x linux/386 linux/arm/v7 linux/arm/v6  需要注意的是：在进行跨平台构建时，如果使用了基础镜像，需要确保对应的基础镜像也有对应的架构，否则会构建失败。\n","date":"Apr 17","permalink":"/post/build-docker-image-in-multi-archs-with-github-actions/","tags":["GitHub","Docker Image"],"title":"使用GiHub Actions构建多架构Docker镜像"},{"categories":["Tech"],"contents":"EFI开源托管在GitHub：Dell-Optiplex-5070mff-Hackintosh\n配置介绍 硬件配置：\n 准系统: Dell OptiPlex 5070 Micro Form Factor CPU: Intel® Core™ i5-9500T Processor 核显: Intel® UHD Graphics 630 内存: 8GB DDR4 2666 * 2 双通道 硬盘: KIOXIA RC10 NVME SSD 500G Wi-Fi \u0026amp; Bluetooth: DW1820A 声卡: Realtek ALC255(3234) 板载网卡: Intel I219-LM7  接口配置：\n前面板：\n 通用音频接口 有线音频输出 Type C(USB3.1 Gen2 PowerShare) 注：不是雷电接口 Type-A USB接口(USB 3.1 Gen1 PowerShare)  后面板：\n RJ-45网线接口 Type-A USB接口(USB 3.1 Gen1) * 4 DP接口 * 2  正常功能  CPU睿频 核显加速 Airdrop \u0026amp; Airplay \u0026amp; Handoff 所有USB接口 有线及无线网 扬声器 \u0026amp; 通用音频接口 \u0026amp; 有线音频输出 睡眠  安装前准备 安装黑苹果前需要使用GRUB，将关闭CFG锁和设置预分配的DVMT内存到64M。\n将GRUB的EFI文件夹放入U盘根目录，通过U盘启动，输入如下两行命令：\n// Disable CFG lock setup_var 0x5BE 0x00 // Set Pre-Allocated DVMT to 64M setup_var 0x8DC 0x02 系统安装镜像请到黑果小兵的部落阁下载\n遇到的问题   核显驱动\n戴尔主板的显示总线在1号和2号，注入核显型号后还需要注入总线ID，因为主板上只有两个DP接口，所以把con2屏蔽掉了。但5070MFF主板上有接口可以扩展出新的视频输出，如果有需要需要自己测试。\n  DW1820A的Wi-Fi驱动\n使用该网卡时需要屏蔽4个pin引脚，屏蔽后插入即可直接驱动Wi-Fi\n具体需要屏蔽的pin引脚请看，使用胶带进行屏蔽即可：DW1820A/BCM94350ZAE/BCM94356ZEPA50DX插入的正确姿势\n  ","date":"Mar 10","permalink":"/post/dell-optiplex-5070mff-hackintosh/","tags":["Hackintosh","Dell"],"title":"戴尔5070MFF黑苹果体验"},{"categories":["Tech"],"contents":"前言 最近一段时间在写C语言的课程设计，之前在用 Golang 的时候，Golang 自带单元测试，用起来非常舒服，而C语言不使用框架写测试则会很麻烦，下面通过一个简单的项目来实践在C语言中进行单元测试。\n项目中使用 CMocka 作为单元测试框架，使用 CodeCov 检查代码覆盖率。\n完整项目代码可以在 GitHub 上查看：c-unittest-example\n项目目录 . ├── CMakeLists.txt ├── Makefile ├── README.md ├── cmake │ ├── CMocka.cmake │ └── CodeCov.cmake ├── include │ └── add.h ├── src │ └── add.c └── test ├── CMakeLists.txt ├── add_tests.c └── test.h 4 directories, 10 files 目录说明 cmake: 存放 CMake 的模块文件，包括 CMocka 和 CodeCov。\ninclude: 项目头文件 src: 项目源代码 test: 单元测试代码\n项目设置文件 Makefile 用于便携执行单元测试和构建程序\n.PHONY: cmake test BUILD_TYPE ?= Debug BUILD_DIR ?= cmake-build-$(shell echo $(BUILD_TYPE) | tr \u0026#39;[:upper:]\u0026#39; \u0026#39;[:lower:]\u0026#39;) CODECOV ?= OFF IWYU ?= ON TEST_SUITES = add_tests # 清理文件 clean: @rm -rf $(BUILD_DIR) # 创建 cmake-build-debug，并在里面执行 cmake cmake: @mkdir -p $(BUILD_DIR) \u0026amp;\u0026amp; cd $(BUILD_DIR) \u0026amp;\u0026amp; cmake -DCODE_COVERAGE=$(CODECOV) -DIWYU=$(IWYU) -DCMAKE_BUILD_TYPE=$(BUILD_TYPE) -j 4 .. # 构建文件 build: cmake @cd $(BUILD_DIR) \u0026amp;\u0026amp; make project -j 4 # 进行单元测试 test: @cd $(BUILD_DIR) \u0026amp;\u0026amp; make $(TEST_SUITES) test CTEST_OUTPUT_ON_FAILURE=TRUE # 测试代码覆盖率 coverage: test @cd $(BUILD_DIR) \u0026amp;\u0026amp; make codecov CMAKE_BUILD_TYPE=$(BUILD_TYPE) cmake/CMocka.cmake 添加 CMocka 到项目中\ninclude(ExternalProject)# 添加额外的项目，即 CMocka ExternalProject_Add(cmocka_ep URL https://git.cryptomilk.org/projects/cmocka.git/snapshot/cmocka-1.1.5.tar.gz CMAKE_ARGS -DCMAKE_BUILD_TYPE=${CMAKE_BUILD_TYPE} -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME} -DBUILD_STATIC_LIB=ON -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY_DEBUG:PATH=Debug -DCMAKE_ARCHIVE_OUTPUT_DIRECTORY_RELEASE:PATH=Release -DUNIT_TESTING=OFF BUILD_COMMAND $(MAKE) cmocka-static INSTALL_COMMAND \u0026#34;\u0026#34;)# 全局作用域下添加 cmocka 静态库 add_library(cmocka STATIC IMPORTED GLOBAL)# 获取二进制文件夹路径 ExternalProject_Get_Property(cmocka_ep binary_dir)# 分别设置正常、Debug、Release的导入路径 set_property(TARGET cmocka PROPERTY IMPORTED_LOCATION \u0026#34;${binary_dir}/src/libcmocka-static.a\u0026#34;)set_property(TARGET cmocka PROPERTY IMPORTED_LOCATION_DEBUG \u0026#34;${binary_dir}/src/Debug/libcmocka-static.a\u0026#34;)set_property(TARGET cmocka PROPERTY IMPORTED_LOCATION_RELEASE \u0026#34;${binary_dir}/src/Release/libcmocka-static.a\u0026#34;)# 将 cmocka_ep 依赖添加到 cmocka add_dependencies(cmocka cmocka_ep)# 获取 cmocka_ep 的源文件路径 ExternalProject_Get_Property(cmocka_ep source_dir)# 全局作用域下设置头文件引入路径 set(CMOCKA_INCLUDE_DIR ${source_dir}/include GLOBAL)cmake/CodeCov.cmake 添加 CodeCov 到项目中\n# 寻找 gcovr find_program(GCOVR_PATH gcovr PATHS ${CMAKE_SOURCE_DIR}/scripts/test)# 设置 CMake 时的参数 set(CMAKE_C_FLAGS_CODECOV \u0026#34;-O0 -g --coverage\u0026#34; CACHE INTERNAL \u0026#34;\u0026#34;)# 设为高级变量 mark_as_advanced(CMAKE_C_FLAGS_CODECOV)# 确保是在使用 Debug 来构建 string(TOLOWER ${CMAKE_BUILD_TYPE} current_build_type)if (NOT current_build_type STREQUAL \u0026#34;debug\u0026#34;) message(WARNING \u0026#34;Code coverage results with an optimised (non-Debug) build may be misleading\u0026#34;)endif ()# 如果使用的是 GNU 则链接 gcov 库文件 if (CMAKE_C_COMPILER_ID STREQUAL \u0026#34;GNU\u0026#34;) link_libraries(gcov)endif ()# 添加 CodeCov 编译参数到 CMake set(CMAKE_C_FLAGS \u0026#34;${CMAKE_C_FLAGS} ${CMAKE_C_FLAGS_CODECOV}\u0026#34;)message(STATUS \u0026#34;Appending code coverage compiler flags: ${CMAKE_C_FLAGS_CODECOV}\u0026#34;)# 添加自定义 target add_custom_target(codecov WORKING_DIRECTORY ${PROJECT_BINARY_DIR} COMMENT \u0026#34;Generating code cov report at ${PROJECT_BINARY_DIR}/codecov.xml\u0026#34; # 在 SHELL 中展示代码覆盖率总结  COMMAND ${GCOVR_PATH} --exclude-throw-branches -r .. --object-directory \u0026#34;${PROJECT_BINARY_DIR}\u0026#34; -e \u0026#34;.*/test/.*\u0026#34; -e \u0026#34;.*/usr/.*\u0026#34; --print-summary # 输出到 codecov.xml  COMMAND ${GCOVR_PATH} --xml --exclude-throw-branches -r .. --object-directory \u0026#34;${PROJECT_BINARY_DIR}\u0026#34; -e \u0026#34;.*/test/.*\u0026#34; -e \u0026#34;.*/usr/.*\u0026#34; -o codecov.xml)CMakeLists.txt 设置当前项目\n# CMake 最低版本要求 cmake_minimum_required(VERSION 3.17)# 设置 CMake 模块目录 set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} \u0026#34;${CMAKE_CURRENT_SOURCE_DIR}/cmake\u0026#34;)# 项目名 project(project)# 设置 CodeCov option(CODE_COVERAGE \u0026#34;Enable coverage reporting\u0026#34; OFF)if (CODE_COVERAGE AND CMAKE_C_COMPILER_ID MATCHES \u0026#34;GNU|Clang\u0026#34;) include(CodeCov)endif ()# 设置 include-what-you-use option(IWYU \u0026#34;Run include-what-you-use with the compiler\u0026#34; OFF)if (IWYU)\t# 寻找 iwyu  find_program(IWYU_COMMAND NAMES include-what-you-use iwyu) if (NOT IWYU_COMMAND) message(FATAL_ERROR \u0026#34;CMAKE_IWYU is ON but include-what-you-use is not found!\u0026#34;) endif () # 添加饮用  set(CMAKE_C_INCLUDE_WHAT_YOU_USE \u0026#34;${IWYU_COMMAND};-Xiwyu\u0026#34;)endif ()# 启用测试 enable_testing()# 将源码添加到项目 add_library(project src/add.c)# 设置头文件目录 target_include_directories(project PUBLIC $\u0026lt;INSTALL_INTERFACE:include\u0026gt; $\u0026lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include\u0026gt; PRIVATE ${CMAKE_CURRENT_SOURCE_DIR}/src)# 添加单元测试子文件 add_subdirectory(test)test/CMakeLists.txt 设置项目的单元测试\n# 引入 CMocka.cmake include(CMocka)# 引入 Cmocka 头文件 include_directories(${CMOCKA_INCLUDE_DIR})# 用于快捷添加测试，_testName 为单元测试的文件名，不带后缀 function(add_test_suite _testName) add_executable(${_testName} ${_testName}.c) target_link_libraries(${_testName} project cmocka) add_test(${_testName} ${CMAKE_CURRENT_BINARY_DIR}/${_testName})endfunction()add_test_suite(add_tests)项目源码 这里实现一个可以传可变参数的加法函数。\nadd.h #ifndef PROJECT_ADD_H #define PROJECT_ADD_H  int add(int count, ...); #endif //PROJECT_TEST_H add.c #include \u0026#34;add.h\u0026#34;#include \u0026lt;stdarg.h\u0026gt; int add(int count, ...) { va_list arg_ptr; va_start(arg_ptr, count); int sum = 0; for (int i = 0; i \u0026lt; count; ++i) { int tmp = va_arg(arg_ptr, int); sum += tmp; } va_end(arg_ptr); return sum; } test/test.h 引入 CMocka 所需的头文件\n#ifndef PROJECT_TEST_H #define PROJECT_TEST_H  #include \u0026lt;stdarg.h\u0026gt;#include \u0026lt;stddef.h\u0026gt;#include \u0026lt;setjmp.h\u0026gt;#include \u0026lt;cmocka.h\u0026gt; int run_all_tests(void); int main() { return run_all_tests(); } #endif //PROJECT_TEST_H test/add_tests.c #include \u0026#34;test.h\u0026#34;#include \u0026#34;add.h\u0026#34; static void test_add_1(void **state) { int sum = add(1, 1); assert_int_equal(1, sum); } static void test_add_2(void **state) { int sum = add(2, 1, 2); assert_int_equal(3, sum); } static void test_add_more(void **state) { int sum = add(6, 1, 2, 3, 4, 5, 6); assert_int_equal(21, sum); } int run_all_tests() { const struct CMUnitTest tests[] = { cmocka_unit_test(test_add_1), cmocka_unit_test(test_add_2), cmocka_unit_test(test_add_more), }; return cmocka_run_group_tests(tests, NULL, NULL); } 进行测试 项目根目录下执行\nCODECOV=ON IWYU=OFF make cmake coverage 执行效果如下到 CodeCov 上创建项目，获取 TOKEN，执行如下命令上传测试报告\necho \u0026#34;YOUR TOKEN\u0026#34; \u0026gt; .cc_token bash \u0026lt;(curl -s https://codecov.io/bash) -f cmake-build-debug/codecov.xml -t @.cc_token 项目也可以使用 GitHub Actions 进行自动化构建和上传\n在项目中设置 secrets.CODECOV_TOKEN 即可，详细设置可以查看 .github/workflows/workflow.yml\n","date":"Dec 22","permalink":"/post/c-unittest-example/","tags":["C","CMocka","CodeCov","CMake"],"title":"C语言项目单元测试实践"},{"categories":null,"contents":"","date":"Nov 27","permalink":"/articles/","tags":null,"title":"Articles"},{"categories":["学习"],"contents":"通过劫持系统调用表，将原有系统调用替换成自定义系统调用。\n使用系统为 Ubuntu，内核版本为 4.4.0-93-generic\n劫持系统调用有风险，请不要在实体机上尝试。\n前言 添加系统调用有两种方法\n 修改内核源代码，并重新编译内核  这种耗时耗力，比较麻烦，但是是在原有的系统调用中插入新的系统调用，不会出现冲突等问题。\n 通过内核模块重新映射系统调用地址  通过拦截系统调用表，将某个系统调用的地址修改成我们自定义的系统系统调用。\n什么是系统调用表 在 Linux 中每个系统调用都有相应的系统调用号作为唯一的标识，内核维护一张系统调用表：sys_call_table。\n在 64 位系统中，sys_call_table 的定义在 entry/syscall_64.c#L25\nasmlinkage const sys_call_ptr_t sys_call_table[__NR_syscall_max+1] = { [0 ... __NR_syscall_max] = \u0026amp;sys_ni_syscall, #include \u0026lt;asm/syscalls_64.h\u0026gt;}; 其中 #include \u0026lt;asm/syscalls_64.h\u0026gt; 是通过 entry/syscalls/Makefile 以 entry/syscalls/syscall_64.tbl 为源文件编译生成的。\nout := $(obj)/../../include/generated/asm syscall64 := $(srctree)/$(src)/syscall_64.tbl systbl := $(srctree)/$(src)/syscalltbl.sh $(out)/syscalls_64.h: $(syscall64) $(systbl) $(call if_changed,systbl) Makefile 通过 entry/syscalls/syscalltbl.sh 将 syscall_64.tbl 格式化成 __SYSCALL_${abi}($nr, $entry, $compat)\n#!/bin/sh  in=\u0026#34;$1\u0026#34; out=\u0026#34;$2\u0026#34; grep \u0026#39;^[0-9]\u0026#39; \u0026#34;$in\u0026#34; | sort -n | ( while read nr abi name entry compat; do abi=`echo \u0026#34;$abi\u0026#34; | tr \u0026#39;[a-z]\u0026#39; \u0026#39;[A-Z]\u0026#39;` if [ -n \u0026#34;$compat\u0026#34; ]; then echo \u0026#34;__SYSCALL_${abi}($nr, $entry, $compat)\u0026#34; elif [ -n \u0026#34;$entry\u0026#34; ]; then echo \u0026#34;__SYSCALL_${abi}($nr, $entry, $entry)\u0026#34; fi done ) \u0026gt; \u0026#34;$out\u0026#34; 生成后的 syscall_64.h 内容截取如下：\n__SYSCALL_COMMON(0, sys_read, sys_read) __SYSCALL_COMMON(1, sys_write, sys_write) 再看回 entry/syscall_64.c：\n#define __SYSCALL_COMMON(nr, sym, compat) __SYSCALL_64(nr, sym, compat) #define __SYSCALL_64(nr, sym, compat) [nr] = sym, 所以可以得到 sys_call_table 的展开如下：\nasmlinkage const sys_call_ptr_t sys_call_table[__NR_syscall_max+1] = { [0 ... __NR_syscall_max] = \u0026amp;sys_ni_syscall, [0] = sys_read, [1] = sys_write, ... }; 所以可以把 sys_call_table 看作一个数组，索引为系统调用号，值为系统调用函数的起始地址。\n获取 sys_call_table 地址  通过 /boot/System.map 获取 通过 /proc/kallsyms 获取 通过暴力搜索获取  前面两种方式基本一致，都是通过读取文件并过滤的方式获取。\n/boot/System.map 包含整个内核镜像的符号表。\n/proc/kallsyms 不仅包含内核镜像符号表，还包含所有动态加载模块的符号表。\n# /boot/System.map root@0xDayServer:~# cat /boot/System.map-$(uname -r) | grep sys_call_table ffffffff81a001c0 R sys_call_table ffffffff81a01520 R ia32_sys_call_table # /proc/kallsyms root@0xDayServer:~# cat /proc/kallsyms | grep sys_call_table ffffffff81a001c0 R sys_call_table ffffffff81a01520 R ia32_sys_call_table 如果要在 LKM 中 使用的话，可以将地址写在宏定义上，再进行调用。\n#define SYS_CALL_TABLE ffffffff81a001c0 但在不同的系统上都得进行修改并重新编译，非常麻烦。\n暴力搜索 注意：在 Linux 内核 v4.17及之后 sys_close 就不再被导出。\n前面提到 sys_call_table 是一个数组，索引为系统调用号，值为系统调用函数的起始地址。\n内核内存空间的起始地址 PAGE_OFFSET 变量和 sys_close 系统调用在内核模块中是可见的。系统调用号在同一ABI（x86与x64属于不同ABI）中是高度后向兼容的，可以直接引用（如 __NR_close ）。我们可以从内核空间起始地址开始，把每一个指针大小的内存假设成 sys_call_table 的地址，并用 __NR_close 索引去访问它的成员，如果这个值与 sys_close 的地址相同的话，就可以认为找到了 sys_call_table 的地址。\n更多有关 PAGE_OFFSET 的内容请看：[ARM64 Linux 内核虚拟地址空间](https://geneblue.github.io/2017/04/02/ARM64 Linux 内核虚拟地址空间/)\n下面来看搜索 sys_call_table 的函数：\nULONG_MAX 为 0xFFFFFFFFUL，即 unsigned long 的最大值\nunsigned long **get_sys_call_table(void) { unsigned long **entry = (unsigned long **)PAGE_OFFSET; for (;(unsigned long)entry \u0026lt; ULONG_MAX; entry += 1) { if (entry[__NR_close] == (unsigned long *)sys_close) { return entry; } } return NULL; } 劫持系统调用 写保护 当我们获取到了 sys_call_table 的地址时，并不能直接进行操作，会报错且无法写入，因为在内存中有写保护，这个特性可以通过 CR0 寄存器控制。\nCR0 的第16位比特是写保护，设置时，即使权限级别为0（Linux 有4个权限级别，从0到3，0为最高级。等级0也被称为内核模式），也不能写入只读页。\n我们可以通过 read_cr0 和 write_cr0 这两个函数，来读取和写入 CR0，同时通过 Linux 内核提供的接口 set_bit 和 clear_bit 来操作比特。\n关闭写保护，将第16个比特置为0。\nvoid disable_write_protection(void) { unsigned long cr0 = read_cr0(); clear_bit(16, \u0026amp;cr0); write_cr0(cr0); } 开启写保护，将第16个比特置为1。\nvoid enable_write_protection(void) { unsigned long cr0 = read_cr0(); set_bit(16, \u0026amp;cr0); write_cr0(cr0); } 模块代码 /** * @file nice.c * @author WingLim * @date 2020-03-05 * @version 0.1 * @brief 读取及修改一个进程的 nice 值，并返回最新的 nice 值及优先级 prio 的模块化实现 */ #include \u0026lt;linux/init.h\u0026gt;#include \u0026lt;linux/kernel.h\u0026gt;#include \u0026lt;linux/module.h\u0026gt;// 下面这些头文件为自定义系统调用要用到的 #include \u0026lt;linux/pid.h\u0026gt;#include \u0026lt;linux/sched.h\u0026gt;#include \u0026lt;linux/syscalls.h\u0026gt;#include \u0026lt;linux/uaccess.h\u0026gt;#include \u0026lt;linux/unistd.h\u0026gt; // 这里是随便挑了一个系统调用来劫持，224 为 timer_gettime #define the_syscall_num 224  MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;WingLim\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A module to read or set nice value\u0026#34;); MODULE_VERSION(\u0026#34;0.1\u0026#34;); // 用于保存 sys_call_table 地址 unsigned long **sys_call_table; // 用于保存被劫持的系统调用 static int (*anything_saved)(void); // 从内核起始地址开始搜索内存空间来获得 sys_call_table 的内存地址 unsigned long **get_sys_call_table(void) { unsigned long **entry = (unsigned long **)PAGE_OFFSET; for (;(unsigned long)entry \u0026lt; ULONG_MAX; entry += 1) { if (entry[__NR_close] == (unsigned long *)sys_close) { return entry; } } return NULL; } void disable_write_protection(void) { unsigned long cr0 = read_cr0(); clear_bit(16, \u0026amp;cr0); write_cr0(cr0); } void enable_write_protection(void) { unsigned long cr0 = read_cr0(); set_bit(16, \u0026amp;cr0); write_cr0(cr0); } // 这个是用来获取进程的 prio，代码来自 task_prio // 因为这个函数没有导出，所以拷贝一份到源码里 int get_prio(const struct task_struct *p) { return p-\u0026gt;prio - MAX_RT_PRIO; } asmlinkage long sys_setnice(pid_t pid, int flag, int nicevalue, int __user * prio, int __user * nice) { struct pid * kpid; struct task_struct * task; int nicebef; int priobef; kpid = find_get_pid(pid); // 获取 pid  task = pid_task(kpid, PIDTYPE_PID); // 返回 task_struct  nicebef = task_nice(task); // 获取进程当前 nice 值  priobef = get_prio(task); // 获取进程当前 prio 值  if(flag == 1){ set_user_nice(task, nicevalue); printk(\u0026#34;nice value edit before：%d\\tedit after：%d\\n\u0026#34;, nicebef, nicevalue); return 0; } else if(flag == 0){ copy_to_user(nice, (const void*)\u0026amp;nicebef, sizeof(nicebef)); copy_to_user(prio, (const void*)\u0026amp;priobef, sizeof(priobef)); printk(\u0026#34;nice of the process：%d\\n\u0026#34;, nicebef); printk(\u0026#34;prio of the process：%d\\n\u0026#34;, priobef); return 0; } printk(\u0026#34;the flag is undefined!\\n\u0026#34;); return EFAULT; } static int __init init_addsyscall(void) { // 关闭写保护  disable_write_protection(); // 获取系统调用表的地址  sys_call_table = get_sys_call_table(); // 保存原始系统调用的地址  anything_saved = (int(*)(void)) (sys_call_table[the_syscall_num]); // 将原始的系统调用劫持为自定义系统调用  sys_call_table[the_syscall_num] = (unsigned long*)sys_setnice; // 恢复写保护  enable_write_protection(); printk(\u0026#34;hijack syscall success\\n\u0026#34;); return 0; } static void __exit exit_addsyscall(void) { // 关闭写保护  disable_write_protection(); // 恢复原来的系统调用  sys_call_table[the_syscall_num] = (unsigned long*)anything_saved; // 恢复写保护  enable_write_protection(); printk(\u0026#34;resume syscall\\n\u0026#34;); } module_init(init_addsyscall); module_exit(exit_addsyscall); 添加 Makefile obj-m+=nice.o KDIR = /lib/modules/$(shell uname -r)/build all: make -C $(KDIR) M=$(PWD) modules clean: make -C $(KDIR) M=$(PWD) clean 编译模块并启用 # 编译 root@0xDayServer:~/dev/kernel/nice# make make -C /lib/modules/4.4.0-93-generic/build/ M=/root/dev/kernel/nice modules make[1]: Entering directory `/usr/src/linux-headers-4.4.0-93-generic\u0026#39; CC [M] /root/dev/kernel/nice/nice.o Building modules, stage 2. MODPOST 1 modules CC /root/dev/kernel/nice/nice.mod.o LD [M] /root/dev/kernel/nice/nice.ko make[1]: Leaving directory `/usr/src/linux-headers-4.4.0-93-generic\u0026#39; # 插入模块 root@0xDayServer:~/dev/kernel/nice# insmod nice.ko 模块测试代码 /*test.c*/ #define _GNU_SOURCE #include \u0026lt;unistd.h\u0026gt;#include \u0026lt;sys/syscall.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#define __NR_mysetnice 224 //系统调用号  int main() { pid_t tid; int nicevalue; int prio = 0; int nice = 0; tid = getpid(); syscall(__NR_mysetnice,tid,0,-5,\u0026amp;prio,\u0026amp;nice);//read  printf(\u0026#34;pid: %d\\nprio: %d\\nnice: %d\\n\u0026#34;, tid, prio,nice); syscall(__NR_mysetnice,tid,1,-5,\u0026amp;prio,\u0026amp;nice);//set  printf(\u0026#34;pid: %d\\nprio: %d\\nnice: %d\\n\u0026#34;, tid, prio,nice); syscall(__NR_mysetnice,tid,0,-5,\u0026amp;prio,\u0026amp;nice);//read  printf(\u0026#34;pid: %d\\nprio: %d\\nnice: %d\\n\u0026#34;, tid, prio,nice); printf(\u0026#34;*******************************\\n\u0026#34;); syscall(__NR_mysetnice,tid,0,-15,\u0026amp;prio,\u0026amp;nice);//read  printf(\u0026#34;pid: %d\\nprio: %d\\nnice: %d\\n\u0026#34;, tid, prio,nice); syscall(__NR_mysetnice,tid,1,-15,\u0026amp;prio,\u0026amp;nice);//set  printf(\u0026#34;pid: %d\\nprio: %d\\nnice: %d\\n\u0026#34;, tid, prio,nice); syscall(__NR_mysetnice,tid,0,-15,\u0026amp;prio,\u0026amp;nice);//read  printf(\u0026#34;pid: %d\\nprio: %d\\nnice: %d\\n\u0026#34;, tid, prio,nice); return 0; } 编译测试代码并测试 # 编译 test.c root@0xDayServer:~/dev/kernel/nice# gcc test.c -o test # 执行 root@0xDayServer:~/dev/kernel/nice# ./test pid: 12872 prio: 20 nice: 0 pid: 12872 prio: 20 nice: 0 pid: 12872 prio: 15 nice: -5 ******************************* pid: 12872 prio: 15 nice: -5 pid: 12872 prio: 15 nice: -5 pid: 12872 prio: 5 nice: -15 # 查看模块输出信息 root@0xDayServer:~/dev/kernel/nice# tail /var/log/kern.log Mar 7 03:52:47 0xDayServer kernel: [118009.435431] nice of the process：0 Mar 7 03:52:47 0xDayServer kernel: [118009.435434] prio of the process：20 Mar 7 03:52:47 0xDayServer kernel: [118009.435466] nice value edit before：0\tedit after：-5 Mar 7 03:52:47 0xDayServer kernel: [118009.435475] nice of the process：-5 Mar 7 03:52:47 0xDayServer kernel: [118009.435476] prio of the process：15 Mar 7 03:52:47 0xDayServer kernel: [118009.435481] nice of the process：-5 Mar 7 03:52:47 0xDayServer kernel: [118009.435481] prio of the process：15 Mar 7 03:52:47 0xDayServer kernel: [118009.435485] nice value edit before：-5\tedit after：-15 Mar 7 03:52:47 0xDayServer kernel: [118009.435494] nice of the process：-15 Mar 7 03:52:47 0xDayServer kernel: [118009.435495] prio of the process：5 尾语 这里提到的劫持系统调用，是 RootKit 中的一部分，RootKit 是一组工具，目标是隐藏它自身存在并继续向攻击者提供系统访问。所以我们可以通过劫持系统调用来做一些更有趣的事情，比如劫持 sys_open 来监视文件的创建。\n同时，获取 sys_call_table 也有很多其他方式，比如 IDT（Interrupt Descriptor Table）、MSRs（Model-Specific Registers）在参考三中有它们的实现方式，总之，Linux Kernel 还挺有趣的，接下来再继续探索更多可玩的地方。\n参考  Linux系统调用流程 Linux Rootkit 系列二：基于修改 sys_call_table 的系统调用挂钩 Kernel Mode Hooking Tutorial OS 实验一 | linux 内核编译及添加系统调用 ","date":"Mar 06","permalink":"/post/linux-kernel-practice-hijack-syscall/","tags":["Linux","Kernel","Module"],"title":"Linux Kernel 实践(二)：劫持系统调用"},{"categories":["学习"],"contents":"实现一个简单的 Linux Kernel Module 并通过自定义参数输出信息。\n使用系统为 Ubuntu，内核版本为 4.4.0-93-generic\n什么是内核模块 Loadable Kernel Modules（LKM）即可加载内核模块，LKM可以动态地加载到内存中，无须重新编译内核。所以它经常被用于一些设备的驱动程序，例如声卡，网卡等等。\n内核模块和一般的 C 语言程序不同，它不使用 main() 函数作为入口，并且有如下区别：\n 非顺序执行：内核模块使用初始化函数来进行注册，并处理请求，初始化函数运行后就结束了。 它可以处理的请求类型在模块代码中定义。 没有自动清理：内核模块申请的所有内存，必须要在模块卸载时手动释放，否则这些内存会无法使用，直到重启，也就是说我们需要在模块的卸载函数（也就是下文写到的退出函数）中，将使用的内存逐一释放。 会被中断：内核模块可能会同时被多个程序/进程使用，构建内核模块时要确保发生中断时行为一致和正确。想了解更多请看：Linux 内核的中断机制 更高级的执行特权：通常分配给内核模块的CPU周期比分配给用户空间程序的要多。编写内核模块时要小心，以免模块对系统的整体性能产生负面影响。 不支持浮点：在Linux内核里无法直接进行浮点计算，因为这样做可以省去在用户态与内核态之间进行切换时保存/恢复浮点寄存器 FPU的操作。  构建前的准备 通过包管理安装 Linux 内核头文件\n$ sudo apt update $ apt-cache search linux-headers-$(uname -r) $ apt install linux-headers-$(uname -r) 开始写代码 引入头文件 #include \u0026lt;linux/init.h\u0026gt; // 用于标记函数的宏#include \u0026lt;linux/module.h\u0026gt; //加载内核模块到内核使用的核心头文件#include \u0026lt;linux/kernel.h\u0026gt; // 包含内核使用的类型、宏和函数定义模块信息 MODULE_LICENSE(\u0026#34;GPL\u0026#34;); // 许可类型，它会影响到运行时行为 MODULE_AUTHOR(\u0026#34;WingLim\u0026#34;); // 作者，当使用 modinfo 命令时可见 MODULE_DESCRIPTION(\u0026#34;A simple Linux driver to say hello.\u0026#34;); // 模块描述，参见 modinfo 命令 MODULE_VERSION(\u0026#34;0.1\u0026#34;); // 模块版本 如果没有定义 MODULE_LICENSE ，在编译和加载模块时会报 WARNING: modpost: missing MODULE_LICENSE()\nMODULE_LICENSE 可以选用 “GPL”，“GPL v2”，“GPL and additional rights”，“Dual BSD/GPL”，“Dual MPL/GPL”，“Proprietary” 这几个许可证。更多说明请看：linux/module.h#L209\n初始化函数 static 限制这个函数的可见范围为当前 C 文件\n__init 表示该函数仅在初始化阶段使用，之后释放使用的内存资源：init.h#L7\n@return 执行成功返回 0\n在内核中我们使用 printk() 来打印信息.。printk() 和 printf() 语法一样，但需要先定义消息类型。可用的消息类型可以到 linux/kern_levels.h#L7-#L23 查看\nstatic int __init helloModule_init(void){ printk(KERN_INFO \u0026#34;Hello LKM!\\n\u0026#34;); return 0; } 退出函数 __exit 表示如果这个代码用于一个内置的驱动程序(而不是LKM)，则不需要这个函数。\nstatic void __exit helloModule_exit(void){ printk(KERN_INFO \u0026#34;Goodbye LKM!\\n\u0026#34;); } 初始化\u0026amp;退出模块 定义在 linux/module.h#L75-#L98\nmodule_init(helloModule_init); module_exit(helloModule_exit); 汇总 /*hello.c*/ #include \u0026lt;linux/init.h\u0026gt;#include \u0026lt;linux/module.h\u0026gt;#include \u0026lt;linux/kernel.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;WingLim\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Linux driver to say hello.\u0026#34;); MODULE_VERSION(\u0026#34;0.1\u0026#34;); static int __init helloModule_init(void){ printk(KERN_INFO \u0026#34;Hello LKM!\\n\u0026#34;); return 0; } static void __exit helloModule_exit(void){ printk(KERN_INFO \u0026#34;Goodbye LKM!\\n\u0026#34;); } module_init(helloModule_init); module_exit(helloModule_exit); 编译 添加 Makefile\nobj-m+=hello.o KDIR = /lib/modules/$(shell uname -r)/build all: make -C $(KDIR) M=$(PWD) modules clean: make -C $(KDIR) M=$(PWD) clean 注意：Makefile 的基本语法如下，如果缩进不是 \u0026lt;TAB\u0026gt; 的话，会报错。\n\u0026lt;target\u0026gt;: [ \u0026lt;dependency \u0026gt; ]* [ \u0026lt;TAB\u0026gt; \u0026lt;command\u0026gt; \u0026lt;endl\u0026gt; ]+ # 查看当前文件 root@0xDayServer:~/dev/kernel/hello# ls -l total 8 -rw-r--r-- 1 root root 466 Mar 6 22:53 hello.c -rw-r--r-- 1 root root 154 Mar 6 22:54 Makefile # 编译 root@0xDayServer:~/dev/kernel/hello# make make -C /lib/modules/4.4.0-93-generic/build/ M=/root/dev/kernel/hello modules make[1]: Entering directory `/usr/src/linux-headers-4.4.0-93-generic\u0026#39; CC [M] /root/dev/kernel/hello/hello.o Building modules, stage 2. MODPOST 1 modules CC /root/dev/kernel/hello/hello.mod.o LD [M] /root/dev/kernel/hello/hello.ko make[1]: Leaving directory `/usr/src/linux-headers-4.4.0-93-generic\u0026#39; # 编译后生成的模块文件 root@0xDayServer:~/dev/kernel/hello# ls hello.c hello.ko hello.mod.c hello.mod.o hello.o Makefile modules.order Module.symvers 测试模块 查看模块信息 root@0xDayServer:~/dev/kernel/hello# modinfo hello.ko filename: /root/dev/kernel/hello/hello.ko version: 0.1 description: A simple Linux driver to say hello. author: WingLim license: GPL srcversion: 093C7851C912088AEE5F77C depends: vermagic: 4.4.0-93-generic SMP mod_unload modversions 加载模块 root@0xDayServer:~/dev/kernel/hello# insmod hello.ko root@0xDayServer:~/dev/kernel/hello# lsmod Module Size Used by hello 16384 0 卸载模块 root@0xDayServer:~/dev/kernel/hello# rmmod hello 查看 printk() 输出信息  使用 dmesg 命令  root@0xDayServer:~/dev/kernel/hello# dmesg [100339.744628] Hello LKM! [100432.211044] Goodbye LKM! 查看内核日志  root@0xDayServer:~/dev/kernel/hello# tail /var/log/kern.log Mar 6 22:58:16 0xDayServer kernel: [100339.744628] Hello LKM! Mar 6 22:59:49 0xDayServer kernel: [100432.211044] Goodbye LKM! 自定义参数 将 hello.c 修改如下\n/*hello.c*/ #include \u0026lt;linux/init.h\u0026gt;#include \u0026lt;linux/module.h\u0026gt;#include \u0026lt;linux/kernel.h\u0026gt; MODULE_LICENSE(\u0026#34;GPL\u0026#34;); MODULE_AUTHOR(\u0026#34;WingLim\u0026#34;); MODULE_DESCRIPTION(\u0026#34;A simple Linux driver to say hello.\u0026#34;); MODULE_VERSION(\u0026#34;0.1\u0026#34;); static char *name = \u0026#34;LKM\u0026#34;; module_param(name, charp, S_IRUGO); MODULE_PARM_DESC(name, \u0026#34;The name to display in /var/log/kern.log\u0026#34;); static int __init helloModule_init(void){ printk(KERN_INFO \u0026#34;Hello %s!\\n\u0026#34;, name); return 0; } static void __exit helloModule_exit(void){ printk(KERN_INFO \u0026#34;Goodbye %s!\\n\u0026#34;, name); } module_init(helloModule_init); module_exit(helloModule_exit); 解析 static char *name = \u0026quot;LKM\u0026quot;; 声明了一个全局静态字符指针变量 name，默认值为\u0026quot;LKM\u0026quot;\n在内核模块中应该尽量避免使用全局变量，因为全局变量会被整个内核共享。所以应该使用 static 来限制变量在模块中的作用域，如果一定要使用全局变量的话，最好给这个变量加上前缀，以确保它在内核中是唯一的。\nmodule_param(name, type, permissions) 定义在 linux/moduleparam.h#L125\nname 名字：向用户显示的参数名称和模块中的变量名称\ntype 参数类型：byte, short, ushort, int, uint, long, ulong, charp, bool, invbool\npermissions 权限：值为 0 时，禁用该项，0444 所有人可读，0644 root用户可写，这里的写法和文件权限一致。\nMODULE_PARM_DESC 参数描述，会显示在 modinfo 中\n调用 root@0xDayServer:~/dev/kernel/hello# insmod hello.ko name=World root@0xDayServer:~/dev/kernel/hello# dmesg [103386.179203] Hello World! 参考  Writing a Linux Kernel Module — Part 1: Introduction linux 下的浮点运算 Linux Device Drivers : 3rd Edition ","date":"Mar 06","permalink":"/post/linux-kernel-practice-hello/","tags":["Linux","Kernel","Module"],"title":"Linux Kernel 实践(一)：Hello LKM"}]